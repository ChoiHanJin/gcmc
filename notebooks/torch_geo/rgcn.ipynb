{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import gzip\n",
    "# rdfはWeb上のリンクをグラフ構造で表してWeb自体を\n",
    "# 体系的な知識構造にしようと言うところででてきたやつ\n",
    "import rdflib as rdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "from torch_geometric.data import (InMemoryDataset, Data, \n",
    "                                  download_url, extract_tar)\n",
    "from torch_geometric.utils import one_hot\n",
    "\n",
    "\n",
    "# rgcn\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(InMemoryDataset):\n",
    "    url = 'https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/{}.tgz'\n",
    "    \n",
    "    def __init__(self, root, name, transform=None, pre_transform=None):\n",
    "        assert name in ['AIFB', 'AM', 'MUTAG', 'BGS']\n",
    "        self.name = name.lower()\n",
    "        super(Entities, self).__init__(root, transform, pre_transform)\n",
    "        # processed_path[0]は処理された後のデータで，process methodで定義される\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    \"\"\"\n",
    "    ここで定義されている@propertyはclass_name.propertyとして\n",
    "    アクセスできるようにしているデコレータで，計算してからself.~~と\n",
    "    今まで書いていたものを，このようにスマートに定義することが可能らしい．いいね．\n",
    "    知らなかったのは多分やばい．．．\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def num_relations(self):\n",
    "        return self.data.edge_type.max().item() + 1\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.data.train_y.max().item() + 1\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\n",
    "            '{}_stripped.nt.gz'.format(self.name),\n",
    "            'completeDataset.tsv',\n",
    "            'trainingSet.tsv',\n",
    "            'testSet.tsv'\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "    \n",
    "    \n",
    "    def download(self):\n",
    "        path = download_url(self.url.format(self.name), self.root)\n",
    "        extract_tar(path, self.raw_dir)\n",
    "        os.unlink(path)\n",
    "        \n",
    "    def triples(self, graph, relation=None):\n",
    "        for s, p, o in graph.triples((None, relation, None)):\n",
    "            yield s, p, o\n",
    "            \n",
    "    def process(self):\n",
    "        graph_file, task_file, train_file, test_file = self.raw_paths\n",
    "        print(self.raw_paths)\n",
    "        \n",
    "        g = rdf.Graph()\n",
    "        with gzip.open(graph_file, 'rg') as f:\n",
    "            g.parse(file=f, format='nt')\n",
    "            \n",
    "        relations = sorted(set(g.predicates()), key=lambda rel: -freq(rel))\n",
    "        subjects = set(g.subjects())\n",
    "        objects = set(g.objects())\n",
    "        nodes = list(subjects.union(objects))\n",
    "        \n",
    "        relations_dict = {rel: i for i in enumerate(list(relations))}\n",
    "        nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
    "        \n",
    "        edge_list = []\n",
    "        for s, p, o in g.triples((None, None, None)):\n",
    "            src, dst, rel = nodes_dict[s], nodes_dict[o], relations_dict[p]\n",
    "            edge_list.append([src, dst, 2 * rel])\n",
    "            edge_list.append([dst, src, 2 * rel + 1])\n",
    "            \n",
    "        edge_list = sorted(edge_list, key=lambda x: (x[0], x[1], x[2]))\n",
    "        edge = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "        edge_index, edge_type = edge[:2], edge[2]\n",
    "        \n",
    "        oh = one_hot(edge_type, 2 * len(relations), dtype=torch.float)\n",
    "        deg = scatter_add(oh, edge_index[0], dim=0, dim_size=len(nodes))\n",
    "        index = edge_type + torch.arange(len(edge_list)) * 2 * len(relations)\n",
    "        edge_norm = 1 / deg[edge_index[0]].view(-1)[index]\n",
    "        \n",
    "        if self.name == 'am':\n",
    "            label_header = 'label_category'\n",
    "            nodes_header = 'proxy'\n",
    "        elif self.name == 'aifb':\n",
    "            label_header = 'label_affiliation'\n",
    "            nodes_header = 'person'\n",
    "        elif self.name == 'mutag':\n",
    "            label_header = 'label_mutagenic'\n",
    "            nodes_header = 'bond'\n",
    "        elif self.name == 'bgs':\n",
    "            label_header = 'label_lithogenesis'\n",
    "            nodes_header = 'rock'\n",
    "            \n",
    "            \n",
    "        labels_df = pd.read_csv(task_file, sep='\\t')\n",
    "        labels_set = set(labels_df[label_header].values.tolist())\n",
    "        labels_dict = {lab: i for i, lab in enumerate(list(labels_set))}\n",
    "        nodes_dict = {np.unicode(key): val for key, val in nodes_dict.items()}\n",
    "        \n",
    "        train_labels_df = pd.read_csv(train_file, sep='\\t')\n",
    "        train_indices, train_lables = [], []\n",
    "        for nod, lab in zip(train_labels_df[nodes_header].values,\n",
    "                           train_labels_df[label_header].values):\n",
    "            train_indices.append(nodes_dict[nod])\n",
    "            train_labels.append(labels_dict[lab])\n",
    "            \n",
    "        train_idx = torch.tensor(train_indices, dtype=torch.long)\n",
    "        train_y = torch.tensor(train_labels, dtype=torch.long)\n",
    "        \n",
    "        test_labels_df = pd.read_csv(test_file, sep='\\t')\n",
    "        test_indices, test_labels = [], []\n",
    "        for nod, lab in zip(test_labels_df[nodes_header].values, \n",
    "                            test_labels_df[label_header].values):\n",
    "            test_indices.append(nodes_dict[nod])\n",
    "            test_labels.append(labels_dict[lab])\n",
    "            \n",
    "        test_idx = torch.tensor(test_indices, dytpe=torch.long)\n",
    "        test_y = torch.tensor(test_labels, dtype=torch.long)\n",
    "        \n",
    "        data = Data(edge_index=edge_index)\n",
    "        data.edge_type = edge_type\n",
    "        data.edge_norm = edge_norm\n",
    "        data.train_idx = train_idx\n",
    "        data.train_y = train_y\n",
    "        data.test_idx = test_idx\n",
    "        data.test_y = test_y\n",
    "        \n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}{}()'.format(self.name.upper(), self.__class__.__name__)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-eb2da6218e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     73\u001b[0m         or a ByteTensor.\"\"\"\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             s[self.data.cat_dim(key, item)] = slice(slices[idx],\n\u001b[0;32m---> 99\u001b[0;31m                                                     slices[idx + 1])\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The MUTAG dataset contains graphs representing 188 chemical compounds which are either mutagenic or not mutagenic.\n",
    "So here the task of the classifier is to predict the mutagenicity of the chemical compounds, which is a two class classification problem.\n",
    "\"\"\"\n",
    "name = 'MUTAG'\n",
    "path = './data/MUTAG'\n",
    "dataset = Entities(path, name)\n",
    "data = dataset[0]\n",
    "print(dataset[1])\n",
    "print(dataset.raw_paths)\n",
    "print(data)\n",
    "print(data.edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(size, tensor):\n",
    "    stdv = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_0 \\cdot \\mathbf{x}_i +\n",
    "        \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int): Number of bases used for basis-decomposition.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_relations,\n",
    "                 num_bases,\n",
    "                 bias=True):\n",
    "        super(RGCNConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        self.basis = Param(torch.Tensor(num_bases, in_channels, out_channels))\n",
    "        self.att = Param(torch.Tensor(num_relations, num_bases))\n",
    "        self.root = Param(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.num_bases * self.in_channels\n",
    "        uniform(size, self.basis)\n",
    "        uniform(size, self.att)\n",
    "        uniform(size, self.root)\n",
    "        uniform(size, self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type, edge_norm=None):\n",
    "        print('in_channels: ', self.in_channels)\n",
    "        print('out_channels: ', self.out_channels)\n",
    "        print('num_relations: ', self.num_relations)\n",
    "        print('num_bases: ', self.num_bases)\n",
    "        \n",
    "        print('basis: ', self.basis.shape)\n",
    "        print('att: ', self.att.shape)\n",
    "        print('root: ', self.root.shape)\n",
    "\n",
    "        \"\"\"\"\"\"\n",
    "        if x is None:\n",
    "            x = torch.arange(\n",
    "                edge_index.max().item() + 1,\n",
    "                dtype=torch.long,\n",
    "                device=edge_index.device)\n",
    "\n",
    "        print('x: ', x.shape)\n",
    "        print('edge_index: ', edge_index.shape)\n",
    "        \n",
    "        return self.propagate(\n",
    "            'add', edge_index, x=x, edge_type=edge_type, edge_norm=edge_norm)\n",
    "\n",
    "\n",
    "    def message(self, x_j, edge_type, edge_norm):\n",
    "        w = torch.matmul(self.att, self.basis.view(self.num_bases, -1))\n",
    "        print('w1 ', w.shape)\n",
    "        print('x_j: ', x_j.shape, x_j.min(), x_j.max())\n",
    "        print('edge_type: ', edge_type.shape, edge_type.min(), edge_type.max())\n",
    "        print('edge_norm: ', edge_norm)\n",
    "\n",
    "        # ネットワークの最初の段階で，one-hot vectorを入力した場合\n",
    "        if x_j.dtype == torch.long:\n",
    "            print('torch is long')\n",
    "            w = w.view(-1, self.out_channels)\n",
    "            print('w2: ', w.shape)\n",
    "            index = edge_type * self.in_channels + x_j\n",
    "            print('index: ', index.shape)\n",
    "            out = w[index]\n",
    "            print('out: ', out.shape)\n",
    "            return out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "        \n",
    "        # ネットワークの中間層の段階で，中間特徴量を入力した場合\n",
    "        else:\n",
    "            print('torch is not long')\n",
    "            w = w.view(self.num_relations, self.in_channels, self.out_channels)\n",
    "            w = w[edge_type]\n",
    "            out = torch.bmm(x_j.unsqueeze(1), w).squeeze(-2)\n",
    "            return out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # propagateで指定されたaggregateが行われた結果が，aggr_outとしてくる．\n",
    "        print('aggr_out: ', aggr_out.shape, aggr_out.min(), aggr_out.max())\n",
    "        print('x: ', x.shape, x.min(), x.max())\n",
    "        print('root: ', self.root.shape, self.root.min(), self.root.max())\n",
    "        # ネットワークの最初の段階で，one-hot vectorを入力した場合    \n",
    "        if x.dtype == torch.long:\n",
    "            print('self.root[x]: ', self.root[x].shape)\n",
    "            # root[x]を足して，self-loopを別の重みであることを実現している．\n",
    "            # つまり，rootがself-loopのweightを示している．\n",
    "            out = aggr_out + self.root[x]\n",
    "            \n",
    "        # ネットワークの中間層の段階で，中間特徴量を入力した場合\n",
    "        else:\n",
    "            # rootとxをかけて，Wx(self-loop)を行なっている\n",
    "            out = aggr_out + torch.matmul(x, self.root)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, num_relations={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels,\n",
    "            self.num_relations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = RGCNConv(\n",
    "            data.num_nodes, 16, dataset.num_relations, num_bases=30)\n",
    "        self.conv2 = RGCNConv(\n",
    "            16, dataset.num_classes, dataset.num_relations, num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type, edge_norm):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        print(' ')\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels:  23644\n",
      "out_channels:  16\n",
      "num_relations:  46\n",
      "num_bases:  30\n",
      "basis:  torch.Size([30, 23644, 16])\n",
      "att:  torch.Size([46, 30])\n",
      "root:  torch.Size([23644, 16])\n",
      "x:  torch.Size([23644])\n",
      "edge_index:  torch.Size([2, 148454])\n",
      "w1  torch.Size([46, 378304])\n",
      "x_j:  torch.Size([148454]) tensor(0) tensor(23643)\n",
      "edge_type:  torch.Size([148454]) tensor(0) tensor(45)\n",
      "edge_norm:  None\n",
      "torch is long\n",
      "w2:  torch.Size([1087624, 16])\n",
      "index:  torch.Size([148454])\n",
      "out:  torch.Size([148454, 16])\n",
      "aggr_out:  torch.Size([23644, 16]) tensor(-0.0004, grad_fn=<MinBackward1>) tensor(0.0002, grad_fn=<MaxBackward1>)\n",
      "x:  torch.Size([23644]) tensor(0) tensor(23643)\n",
      "root:  torch.Size([23644, 16]) tensor(-0.0012, grad_fn=<MinBackward1>) tensor(0.0012, grad_fn=<MaxBackward1>)\n",
      "self.root[x]:  torch.Size([23644, 16])\n",
      " \n",
      "in_channels:  16\n",
      "out_channels:  2\n",
      "num_relations:  46\n",
      "num_bases:  30\n",
      "basis:  torch.Size([30, 16, 2])\n",
      "att:  torch.Size([46, 30])\n",
      "root:  torch.Size([16, 2])\n",
      "x:  torch.Size([23644, 16])\n",
      "edge_index:  torch.Size([2, 148454])\n",
      "w1  torch.Size([46, 32])\n",
      "x_j:  torch.Size([148454, 16]) tensor(0., grad_fn=<MinBackward1>) tensor(0.0023, grad_fn=<MaxBackward1>)\n",
      "edge_type:  torch.Size([148454]) tensor(0) tensor(45)\n",
      "edge_norm:  None\n",
      "torch is not long\n",
      "aggr_out:  torch.Size([23644, 2]) tensor(-0.0032, grad_fn=<MinBackward1>) tensor(0.0635, grad_fn=<MaxBackward1>)\n",
      "x:  torch.Size([23644, 16]) tensor(0., grad_fn=<MinBackward1>) tensor(0.0023, grad_fn=<MaxBackward1>)\n",
      "root:  torch.Size([16, 2]) tensor(-0.0424, grad_fn=<MinBackward1>) tensor(0.0422, grad_fn=<MaxBackward1>)\n",
      "\n",
      "torch.Size([272])\n",
      "torch.Size([68])\n",
      "torch.Size([23644, 2])\n"
     ]
    }
   ],
   "source": [
    "out = model(data.edge_index, data.edge_type, data.edge_norm)\n",
    "print('')\n",
    "print(data.train_idx.shape)\n",
    "print(data.test_idx.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type, data.edge_norm)\n",
    "    # train_maskとtest_maskっぽいのが使用されているのは，ここ\n",
    "    F.nll_loss(out[data.train_idx], data.train_y).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.edge_index, data.edge_type, data.edge_norm)\n",
    "    pred = out[data.test_idx].max(1)[1]\n",
    "    acc = pred.eq(data.test_y).sum().item() / data.test_y.size(0)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels:  23644\n",
      "out_channels:  16\n",
      "num_relations:  46\n",
      "num_bases:  30\n",
      "basis:  torch.Size([30, 23644, 16])\n",
      "att:  torch.Size([46, 30])\n",
      "root:  torch.Size([23644, 16])\n",
      "x:  torch.Size([23644])\n",
      "edge_index:  torch.Size([2, 148454])\n",
      "w1  torch.Size([46, 378304])\n",
      "x_j:  torch.Size([148454]) tensor(0) tensor(23643)\n",
      "edge_type:  torch.Size([148454]) tensor(0) tensor(45)\n",
      "edge_norm:  None\n",
      "torch is long\n",
      "w2:  torch.Size([1087624, 16])\n",
      "index:  torch.Size([148454])\n",
      "out:  torch.Size([148454, 16])\n",
      "aggr_out:  torch.Size([23644, 16]) tensor(-0.0003, grad_fn=<MinBackward1>) tensor(0.0005, grad_fn=<MaxBackward1>)\n",
      "x:  torch.Size([23644]) tensor(0) tensor(23643)\n",
      "root:  torch.Size([23644, 16]) tensor(-0.0012, grad_fn=<MinBackward1>) tensor(0.0012, grad_fn=<MaxBackward1>)\n",
      "self.root[x]:  torch.Size([23644, 16])\n",
      " \n",
      "in_channels:  16\n",
      "out_channels:  2\n",
      "num_relations:  46\n",
      "num_bases:  30\n",
      "basis:  torch.Size([30, 16, 2])\n",
      "att:  torch.Size([46, 30])\n",
      "root:  torch.Size([16, 2])\n",
      "x:  torch.Size([23644, 16])\n",
      "edge_index:  torch.Size([2, 148454])\n",
      "w1  torch.Size([46, 32])\n",
      "x_j:  torch.Size([148454, 16]) tensor(0., grad_fn=<MinBackward1>) tensor(0.0024, grad_fn=<MaxBackward1>)\n",
      "edge_type:  torch.Size([148454]) tensor(0) tensor(45)\n",
      "edge_norm:  None\n",
      "torch is not long\n",
      "aggr_out:  torch.Size([23644, 2]) tensor(-0.0464, grad_fn=<MinBackward1>) tensor(0.0047, grad_fn=<MaxBackward1>)\n",
      "x:  torch.Size([23644, 16]) tensor(0., grad_fn=<MinBackward1>) tensor(0.0024, grad_fn=<MaxBackward1>)\n",
      "root:  torch.Size([16, 2]) tensor(-0.0428, grad_fn=<MinBackward1>) tensor(0.0416, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    train()\n",
    "#     test_acc = test()\n",
    "#     print('Epoch: {:02d}, Accuracy: {:.4f}'.format(epoch, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_c = 100\n",
    "out_c = 10\n",
    "num_relations = 5\n",
    "\n",
    "ord_basis = [Param(torch.Tensor(1, in_c, out_c)) for _ in range(num_relations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ord_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp, w = 0, 0\n",
    "for relation in range(num_relations):\n",
    "    tmp = ord_basis[relation]\n",
    "    if relation == 0:\n",
    "        w = tmp\n",
    "    else:\n",
    "        w = torch.cat((w, tmp), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_basis[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 148454])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([148454])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = data.edge_index.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int64\n",
      "tensor(230)\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 53, 54}\n",
      "46\n",
      "{0, 8, 3, 7}\n",
      "23644\n",
      "Elapsed:  88.96163487434387\n"
     ]
    }
   ],
   "source": [
    "edge = torch.where(data.edge_index == 23000, \n",
    "                   torch.ones(data.edge_index.shape, \n",
    "                              dtype=torch.int64)*dataset.num_relations, \n",
    "                   torch.zeros(data.edge_index.shape, dtype=torch.int64))\n",
    "\n",
    "\n",
    "print(data.edge_index.dtype, edge.dtype)\n",
    "print(torch.sum(edge[0]))\n",
    "\n",
    "relation = data.edge_type + edge[0]\n",
    "\n",
    "import numpy as np\n",
    "print(set(list(np.array(relation))))\n",
    "\n",
    "print(dataset.num_relations)\n",
    "\n",
    "relation = torch.where(relation >= dataset.num_relations, \n",
    "#                        torch.ones(relation.shape, dtype=relation.dtype),\n",
    "                       relation - dataset.num_relations, \n",
    "                       torch.zeros(relation.shape, dtype=relation.dtype))\n",
    "\n",
    "print(set(list(np.array(relation))))\n",
    "\n",
    "# edge_normは最終的に，edges x 1のshapeになる必要がある．\n",
    "# つまり，target_edgeのもつedgeの本数がわかればよく，\n",
    "# target_edges x 1のshapeで要素にnum_edgesが入る．\n",
    "# そこからそれの逆行列を取り，それをoutに通常の乗算を行う．\n",
    "\n",
    "node_norm = torch.zeros(num_node, dtype=data.edge_index.dtype)\n",
    "print(node_norm.size(0))\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for idx in range(node_norm.size(0)):\n",
    "    edge = torch.where(\n",
    "                        data.edge_index == idx,\n",
    "                        torch.ones(data.edge_index.shape,\n",
    "                                   dtype=data.edge_index.dtype),\n",
    "                        torch.zeros(data.edge_index.shape, \n",
    "                                    dtype=data.edge_index.dtype)\n",
    "                        )\n",
    "    \n",
    "    node_norm[idx] = int(torch.sum(edge) / 2)\n",
    "    \n",
    "print('Elapsed: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can only calculate the mean of floating types. Got Long instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-708a852c7410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Can only calculate the mean of floating types. Got Long instead."
     ]
    }
   ],
   "source": [
    "print(node_norm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.],\n",
      "        [9., 9., 9.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.],\n",
      "        [8., 8., 8.],\n",
      "        [9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(10, 3)\n",
    "b = torch.arange(10, dtype=a.dtype)\n",
    "print(torch.diag(b).shape)\n",
    "c = torch.matmul(torch.diag(b), a)\n",
    "print(c)\n",
    "d = a * b.unsqueeze(1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../data/ml-100k/u1.base'\n",
    "col_names = ['user_id', 'item_id', 'relation', 'ts']\n",
    "train_raw_data = pd.read_csv(train_path, sep='\\t', names=col_names)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 943\n",
    "num_items = 1682\n",
    "num_nodes = num_users + num_items\n",
    "num_edges = 100000\n",
    "num_train_edges = 80000\n",
    "num_test_edges = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_raw_data.drop('ts', axis=1)\n",
    "train_data['user_id'] = train_data['user_id'] - 1\n",
    "train_data['item_id'] = train_data['item_id'] + num_users - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "print(train_data.max()['user_id'])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(num_nodes, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_user = torch.tensor(train_data['user_id'].values)\n",
    "edge_item = torch.tensor(train_data['item_id'].values)\n",
    "edge_index = torch.stack((torch.cat((edge_user, edge_item), 0),\n",
    "                          torch.cat((edge_item, edge_user), 0)), 0)\n",
    "edge_index = edge_index.to(device).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = torch.tensor(train_data['relation'])\n",
    "edge_type = torch.cat((edge_type, edge_type), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2625])\n",
      "torch.Size([2, 160000])\n",
      "torch.Size([160000])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(edge_index.shape)\n",
    "print(edge_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([943, 944, 945,  ..., 942, 942, 942])\n",
      "Elapsed:  6.865419149398804\n",
      "tensor([0.0026, 0.0095, 0.0133,  ..., 0.0060, 0.0060, 0.0060],\n",
      "       dtype=torch.float64) torch.Size([160000])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "edge_norm = copy.deepcopy(edge_index[1])\n",
    "print(edge_norm)\n",
    "\n",
    "start = time.time()\n",
    "for idx in range(num_nodes):\n",
    "    count = (train_data == idx).values.sum()\n",
    "#     count = torch.sum(torch.where(edge_index == idx,\n",
    "#                                   torch.ones(edge_index.shape,\n",
    "#                                              dtype=torch.long),\n",
    "#                                   torch.zeros(edge_index.shape, \n",
    "#                                               dtype=torch.long)))\n",
    "    \n",
    "    edge_norm = torch.where(edge_norm==idx,\n",
    "                            torch.tensor(count),\n",
    "                            edge_norm)\n",
    "\n",
    "print('Elapsed: ', time.time() - start)\n",
    "\n",
    "print(1 / edge_norm.to(torch.double), edge_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "count = (train_data == 942).values.sum()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>951</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>955</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  relation\n",
       "0        0      943         5\n",
       "1        0      944         3\n",
       "2        0      945         4\n",
       "3        0      946         3\n",
       "4        0      947         3\n",
       "5        0      949         4\n",
       "6        0      950         1\n",
       "7        0      951         5\n",
       "8        0      953         2\n",
       "9        0      955         5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
